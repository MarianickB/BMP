{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DecisionTreeCode_MiniProject1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNbFUfJC5sJjw02kcnL9Td8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarianickB/BMP/blob/master/DecisionTreeCode_MiniProject1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yq5S4Bypm6S8"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "class Node:\n",
        "  def __init__(self, data_indices, parent):\n",
        "    self.data_indices = data_indices\n",
        "    self.left = None\n",
        "    self.right = None\n",
        "    self.split_feature = None\n",
        "    self.split_value = None\n",
        "\n",
        "    if parent:\n",
        "      self.depth = parent.depth+1\n",
        "      self.num_classes = parent.num_classes\n",
        "      self.data = parent.data\n",
        "      self.labels = parent.labels\n",
        "      class_prob = np.bincount(self.labels[data_indices], minlength = self.num_classes)\n",
        "      self.class_prob = class_prob/np.sum(class_prob)\n",
        "\n",
        "def greedy(node, cost):\n",
        "  best_cost = np.inf\n",
        "  best_feature = None\n",
        "  best_value = None\n",
        "  num_instances = node.data.shape\n",
        "  num_features = node.data.shape\n",
        "\n",
        "  data_sorted = np.sort(node.data[node.data_indices], axis=0)\n",
        "  test_candidates = (data_sorted[1:]+data_sorted[:-1])/2\n",
        "\n",
        "  for f in range(num_features):\n",
        "    data_f = node.data[node.data_indices, f]\n",
        "    for test in test_candidates[:,f]:\n",
        "      left_indices = node.data_indices[data_f<=test]\n",
        "      right_indices = node.data_indices[data_f>test]\n",
        "\n",
        "      if len(right_indices)==0 or len(left_indices)==0:\n",
        "        continue\n",
        "      left_cost = cost(node.labels[left_indices])\n",
        "      right_cost = cost(node.labels[right_indices])\n",
        "      \n",
        "      num_left = left_indices.shape[0]\n",
        "      num_right = right_indices.shape[0]\n",
        "\n",
        "      totcost = (num_left*left_cost + num_right*right_cost)/num_instances\n",
        "\n",
        "      if totcost<best_cost:\n",
        "        best_cost = totcost\n",
        "        best_feature = f\n",
        "        best_value = test\n",
        "  return best_cost, best_feature, best_value\n",
        "\n",
        "\n",
        "def misclassification_cost(labels):\n",
        "  counts = np.bincount(labels)\n",
        "  class_probs=counts/np.sum(counts)\n",
        "  return 1-np.max(class_probs)\n",
        "\n",
        "def cost_entropy(labels):\n",
        "  class_probs = np.bincounts(labels)/len(labels)\n",
        "  class_probs = class_probs[class_probs>0]\n",
        "  return -np.sum(class_probs*np.log(class_probs))\n",
        "\n",
        "def gini_index(labels):\n",
        "  class_probs = np.bicounts(labels)/len(labels)\n",
        "  return 1-np.sum(np.square(class_probs))\n",
        "\n",
        "class DecisionTree:\n",
        "  def __init__(self, num_classes = None, max_depth=3, cost = misclassification_cost, min_leaf_instances = 1):\n",
        "    self.max_depth = max_depth\n",
        "    self.root = None\n",
        "    self.cost = cost\n",
        "    self.num_classes = num_classes\n",
        "    self.min_leaf_instances = min_leaf_instances\n",
        "\n",
        "  def fit(self, data, labels):\n",
        "    pass\n",
        "  \n",
        "  def predict(self, data_test):\n",
        "    pass\n",
        "\n",
        "def fit(self, data, labels):\n",
        "  self.data = data\n",
        "  self.labels = labels\n",
        "\n",
        "  if self.num_classes is None: \n",
        "    self.num_classes = np.max(labels)+1\n",
        "\n",
        "  self.root = Node(np.arange(data.shape[0]), None)\n",
        "  self.root.data = data\n",
        "  self.root.labels = labels\n",
        "  self.root.num_classes = self.num_classes\n",
        "  self.root.depth = 0\n",
        "  self._fit_tree(self.root)\n",
        "  return self\n",
        "\n",
        "def _fit_tree(self, node):\n",
        "  if node.depth == self.max_depth or len(node.data_indices) <= self.min_leaf_instances:\n",
        "    return\n",
        "  \n",
        "  cost, split_feature, split_value = greedy(node, self.cost)\n",
        "  \n",
        "  if np.isinf(cost):\n",
        "    return\n",
        "  \n",
        "  test = node.data[node.data_indices, split_feature] <=split_value\n",
        "  node.split_feature = split_feature\n",
        "  node.split_value = split_value\n",
        "\n",
        "  left = Node(node.data_indices[test], node)\n",
        "  right = Node(node.data_indices[np.logical_not(test)], node)\n",
        "  self._fit_tree(left)\n",
        "  self._fit_tree(right)\n",
        "\n",
        "DecisionTree.fit = fit\n",
        "DecisionTree._fit_tree = _fit_tree\n",
        "\n",
        "\n",
        "def predict(self, data_test):\n",
        "  class_probs = np.zeros((data_test.shape[0], self.num_classes))\n",
        "  for n, x in enumerate(data_test):\n",
        "    node  = self.root\n",
        "\n",
        "    while node.left:\n",
        "      if x[node.split_feature] <=node.split_value:\n",
        "        node = node.left\n",
        "      else:\n",
        "        node = node.right\n",
        "\n",
        "    class_probs[n,:] = node.class_prob\n",
        "  return class_probs\n",
        "\n",
        "DecisionTree.predict = predict\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experiments for Decision Trees"
      ],
      "metadata": {
        "id": "tcWYdRNCum4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "dataset = datasets.load_iris()\n",
        "x,y = dataset['data'][:,:2], dataset['target']\n",
        "(num_instances, num_features), num_classes = x.shape, np.max(y)+1\n",
        "indx = np.random.permutation(num_instances)\n",
        "\n",
        "x_train,  y_train = x[indx[:200]], y[indx[:200]]\n",
        "\n",
        "x_test,  y_test= x[indx[200:]], y[indx[200:]]\n",
        "\n",
        "\n",
        "tree = DecisionTree(max_depth=30)\n",
        "probs_test = tree.fit(x_train, y_train).predict(x_test)\n",
        "\n",
        "y_pred = np.argmax(probs_test,1)\n",
        "accuracy = np.sum(y_pred == y_test)/y_test.shape[0]\n",
        "print(f'Tree accuracy: {accuracy*100:1f}.')\n",
        "\n",
        "correct = y_test == y_pred\n",
        "incorrect = np.logical_not(correct)\n",
        "\n",
        "plt.scatter(x_train[:,0], x_train[:, 1], c=y_train, marker='o', alpha=.2, label='trainset')\n",
        "plt.scatter(x_test[correct, 0], x_test[correct, 1], marker='.', c=y_pred[correct], label='correct')\n",
        "plt.scatter(x_test[incorrect, 0], x_test[incorrect, 1], marker='x', c=y_test[incorrect], label='incorrect')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "JeoMfl8_ukRE",
        "outputId": "699a4642-8144-44d2-ecb8-3f578c4a9230"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-55dac80353b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprobs_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-08aa0c8313aa>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data, labels)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-08aa0c8313aa>\u001b[0m in \u001b[0;36m_fit_tree\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-08aa0c8313aa>\u001b[0m in \u001b[0;36mgreedy\u001b[0;34m(node, cost)\u001b[0m\n\u001b[1;32m     31\u001b[0m   \u001b[0mtest_candidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdata_sorted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mdata_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'tuple' object cannot be interpreted as an integer"
          ]
        }
      ]
    }
  ]
}